# Домашнее задание к занятию «Микросервисы: подходы» - Мельник Юрий Александрович

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Решение 1
 

## Обоснование выбора инструментов

Мы выбрали **GitHub Enterprise Cloud** (альтернативно --- **GitLab SaaS**) как основную платформу.  
**Почему именно так:** - Это облачные решения, которые удовлетворяют требованию «облачная система». 
- Они поддерживают **Git** и позволяют создавать **отдельные репозитории на каждый сервис**.
- Есть встроенные **CI/CD-конвейеры** (GitHub Actions / GitLab CI) с поддержкой параллельных сборок и тестов.
- Обеспечивается **безопасное хранение секретов** и интеграция с облаками через OIDC.
- Поддерживаются **self-hosted runners**, что даёт гибкость и контроль.
- Реализована возможность **шаблонов пайплайнов** и **кастомных шагов**,
------------------------------------------------------------------------

 1) Структура репозиториев
Мы создадим **отдельный репозиторий на каждый микросервис**, внутри: - `Dockerfile` для сборки контейнера, - CI/CD workflow (`.github/workflows/*.yml` или `.gitlab-ci.yml`), - директория `ci/` для
вспомогательных скриптов. 
------------------------------------------------------------------------

 2) Конвейер окружений
Мы настроим окружения: **Dev → Integration → UAT → Production**.
На каждом этапе будет выполняться:
- Unit-тесты (Dev),
- интеграционные тесты (Integration),
- нагрузочные и приёмочные тесты (UAT),
- выкладка (Production).
Такой процесс соответствует лекции: «цепочка поставки: код → сборка → тесты → установка на тестовый контур → интеграция/нагрузка → ручная приёмка» 
------------------------------------------------------------------------

 3) Секреты и параметры
-   Секреты храним в секрет-хранилище GitHub/GitLab (per-env).
-   Для облаков используем OIDC вместо статических ключей.
-   Для ручных запусков добавляем `workflow_dispatch`/manual jobs с     параметрами (окружение, стратегия выката).
------------------------------------------------------------------------

 4) Шаблоны пайплайнов
Мы создадим общий репозиторий `ci-templates` с reusable workflows (GitHub) или includes (GitLab).\
Это позволит: - поддерживать единый стиль пайплайнов,
- легко добавлять новые сервисы,
- держать несколько конфигураций из одного репозитория.
------------------------------------------------------------------------

 5) Агенты и параллельность
-   Используем облачные раннеры.
-   Для приватных сетей или тяжёлых билдов --- self-hosted runners.
-   Для параллельности используем `matrix` и шардирование тестов.
------------------------------------------------------------------------

6) Контейнерные образы и артефакты
-   Собираем и публикуем Docker-образы в приватный реестр (GHCR/GLCR).
-   Артефакты (отчёты тестов, пакеты) храним в артефактории.
------------------------------------------------------------------------

7) Тесты по пирамиде
В проекте реализована пирамида тестирования, включающая три уровня проверок:
**Unit-тесты** — быстрые и массовые проверки отдельных функций и модулей, запускаются на каждом изменении кода.  
**Интеграционные/сервисные тесты** — проверяют взаимодействие микросервисов и работу API.  
**End-to-End (E2E) тесты** — сквозные сценарии, эмулирующие поведение пользователя.
Такой подход позволяет выявлять большинство ошибок на ранних этапах разработки, сокращает время обратной связи и снижает стоимость исправлений.
Согласно лекции, тесты являются неотъемлемой частью процесса развёртывания, а цепочка сборки должна прерываться как можно раньше при выявлении ошибо
------------------------------------------------------------------------

8) Стратегии выката (CD)
Мы будем использовать:  
- **Rolling** --- плавное обновление,  
- **Blue-Green** --- мгновенное переключение,  
СRolling и Blue-Green --- лучшие базовые стратегии для
продакшена чтобы выкат не сильно был заметен для пользователя
------------------------------------------------------------------------

9) Кастомные шаги  
Мы добавим кастомные шаги: миграции БД, генерация документации, 
прогрев кэшей. - при необходимости  
------------------------------------------------------------------------

10) Безопасность  
-   Включим SAST и dependency scanning.
-   Сканирование Docker-образов (Trivy).
-   Подпись образов и политики admission (OPA/Gatekeeper).
-   Единый подход к аутентификации сервисов (SSO, OAuth2, mTLS, API
    Keys)
------------------------------------------------------------------------



## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Решение 2

Реализуем централизованный сбор и анализ логов на базе **ELK**: агенты (Filebeat/Fluent Bit) на каждом хосте →  
 **Logstash** (парсинг/нормализация) → 
 **Elasticsearch** (центральное хранилище и поиск) → 
  **Kibana** (пользовательский интерфейс). Решение покрывает требования по сбору из *stdout*, гарантии доставки, поиску/фильтрации и предоставлению сохранённых поисков по ссылке.


1) Поток данных**
1. **Агенты на узлах**: Filebeat/Fluent Bit считывают контейнерные логи из *stdout* и системные журналы; добавляют метаданные (сервис, окружение, хост, pod/контейнер при использовании Kubernetes).
2. **Обработка**: данные поступают в **Logstash**, где выполняются парсинг форматов (JSON, текст), нормализация полей, маскирование чувствительных данных и обогащение (при необходимости).
3. **Хранилище и поиск**: **Elasticsearch** индексирует записи и обеспечивает быстрый полнотекстовый поиск и агрегации.
4. **Интерфейс**: **Kibana** предоставляет UI для разработчиков и эксплуатации: поиск, фильтры, визуализации, сохранённые запросы и дашборды (со ссылками для шаринга).

2) Надёжность и доставка**
- Включаем файловые буферы и ретраи на стороне агентов.
- При пиковых нагрузках/жёстких SLA добавляем промежуточный брокер (например, Kafka) между агентами и Logstash для выравнивания нагрузки и гарантированной доставки.
------------------------------------------------------------------------

3) Соответствие требованиям
- **Центральное хранилище со всех хостов** — агенты на каждом узле → Logstash → Elasticsearch (единая точка хранения).
- **Минимальные требования к приложениям** — сбор из *stdout* контейнеров; приложению не требуются изменения.
- **Гарантированная доставка** — буферизация и повторные попытки на агентах; при необходимости — Kafka как «прослойка».
- **Поиск и фильтрация** — полнотекстовый поиск и фильтры в Elasticsearch/Kibana; удобные фасеты по полям/меткам.
- **Пользовательский интерфейс** — Kibana с ролями/правами на пространства/индексы, доступ разработчикам.
- **Сохранённые поиски по ссылке** — сохранение запросов/дашбордов в Kibana и шаринг ссылкой.
------------------------------------------------------------------------

4) Обоснование выбора ELK
1. **Зрелость и распространённость** — стек хорошо известен командам; много документации и экспертизы на рынке.
2. **Гибкая обработка** — Logstash позволяет парсить, нормализовать и обогащать данные под нужды домена.
3. **Мощный поиск/аналитика** — Elasticsearch обеспечивает полнотекстовый посик  и агрегирования (в том числе для отчётности и расследований).
4. **Удобный UX** — Kibana даёт быстрый поиск, визуализации, сохранённые дашборды и общий доступ к ним.
5. **Масштабируемость/HA** — кластеризация Elasticsearch, шардирование и репликация; горизонтальный масштаб.
------------------------------------------------------------------------

5) Эксплуатационные аспекты
- **Политики хранения**: ретеншн по индексам (например, 7–30 дней «горячие» данные, затем «тёплые/холодные» или архив).
- **Безопасность**: разграничение доступа (роли/пространства), маскирование PII на уровне Logstash, шифрование TLS «на входе».
- **Наблюдаемость**: дашборды собственной телеметрии (нагрузка Logstash, состояние кластеров Elasticsearch, объёмы индексов).
- **Стоимость**: планирование диска/IOPS, компрессия, экономия за счёт lifecycle-политик и эконом-класса узлов для «холодных» индексов.
- **Производительность**: бэчинг/конвейер в Logstash, батчи агентов, правильные шаблоны индексов и маппинги полей.
------------------------------------------------------------------------

6) Риски и способы снижения
- **Рост объёма логов** → внедряем фильтрацию «на входе» (drop/редактирование шумных событий), ретеншн и агрегации.
- **«Тяжёлые» запросы в часы пик** → кэширование, ограничения по ролям, выделенные ноды для запросов (hot/warm).
- **Потеря связи с хранилищем** → долговременные файловые буферы агентов; при строгих SLA — Kafka.
- **Чувствительные данные** → маскирование/редакция в Logstash, строгие роли и аудит.
------------------------------------------------------------------------





## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Решение 3  
  
Используем стек **Prometheus/VictoriaMetrics + Grafana + Alertmanager** для метрик и алёртов. 
Сбор с хостов и сервисов обеспечиваем экспортёрами (**node_exporter, cAdvisor, kube-state-metrics**) и метриками приложений (Prometheus client). 
Grafana предоставляет интерфейс для запросов, агрегаций и дашбордов; Alertmanager — маршрутизацию уведомлений и эскалации.
 

**Компоненты**
- **Сбор метрик с хостов**: `node_exporter` (CPU, RAM, диски, сеть), системные метрики.
- **Сервисы и контейнеры**: `cAdvisor` (ресурсы per container/pod), `kube-state-metrics` (состояние объектов k8s). 
- **Специфичные метрики сервисов**: endpoints `/metrics` с Prometheus client (Go/Java/Python/Node.js и др.).
- **Хранилище/агрегации**: **Prometheus** (или кластерная/долгосрочная замена — **VictoriaMetrics**; для HA/долгого хранения возможны **Thanos**/**VM cluster**).
- **Алертинг**: правила в Prometheus, доставка через **Alertmanager** (Telegram/Slack/Email, синхронизация тэгов/лейблов).
- **Интерфейс**: **Grafana** — построение запросов (PromQL/VMQL), агрегаций, переменных, панелей, аннотаций и overview-дашбордов.

**Поток данных**
```
[node_exporter / cAdvisor / kube-state-metrics / app-metrics] 
               → [Prometheus | VictoriaMetrics] 
               → [Grafana] + [Alertmanager]
```
------------------------------------------------------------------------
**Service Discovery**
- Kubernetes, Consul, EC2, static targets — автоматическое обнаружение новых инстансов без ручной правки.
------------------------------------------------------------------------

## Соответствие требованиям
- **Сбор метрик со всех хостов** — `node_exporter` на каждом узле; автообнаружение таргетов.
- **CPU, RAM, HDD, Network (хост)** — готовые метрики `node_exporter` и стандартные дашборды.
- **Ресурсы per service** — `cAdvisor` + лейблы (namespace/deployment/pod/container); агрегации по service/namespace.
- **Специфичные метрики сервисов** — `/metrics` с бизнес-показателями (RPS, latency, ошибки, кэши, очереди).
- **UI: запросы и агрегации** — Grafana (PromQL/VMQL, функции rate(), histogram_quantile(), sum by()).
- **UI: настраиваемые панели** — Grafana dashboards (переменные, теги, сводные экраны SRE/Наблюдаемость).
------------------------------------------------------------------------

## Обоснование выбора
1. **Нативность для микросервисов.** Экспортёры и модель pull-скрейпа хорошо подходят для контейнеров и k8s; добавление сервиса = новая цель с лейблами.
2. **Масштабируемость и стоимость.** VictoriaMetrics/Thanos обеспечивают длительное хранение и горизонтальное масштабирование при умеренной стоимости.
3. **Гибкий алертинг.** Чёткая маршрутизация (по сервисам/тегам/окружениям), эскалации и «тихие окна» (silences).
4. **Удобный UI.** Grafana — де-факто стандарт для запросов, агрегаций и дашбордов; быстрое построение SLO/SLA-панелей.
5. **Расширяемость.** Лёгкое добавление экспортёров (PostgreSQL/Redis/NGINX и т.д.) и пользовательских метрик.
------------------------------------------------------------------------

## Типовые панели и метрики
- **Хосты**: нагрузка CPU (usage/steal/iowait), RAM (util/working set), диски (usage/read/write IOPS, latency), сеть (bw/errors/drops).
- **Сервисы**: RPS, p95/p99 latency (`histogram_quantile()`), error rate, saturation (CPU/Memory/FS per pod), restarts.
- **Инфраструктура**: состояние k8s (ready pods, pending, backoff), лимиты/requests, утилизация по namespace.
- **БД/кэши**: готовые экспортёры (pg_stat, connections, locks; redis hits/misses/latency).
------------------------------------------------------------------------

## Алерты (примеры категорий)
- **Хосты**: CPU > 80% 5м, память < 10% свободно, диск inode/usage, сеть errors/drops.
- **Сервисы**: error_rate > X%, p99 latency выше порога, отсутствие таргета (down), рост restarts.
- **Инфраструктура**: недостаток ресурсов кластера, неготовые ноды/pods, падение реплик.
- **SLO**: бюджет ошибок, нарушение целей доступности/времени ответа.
Маршрутизация: по лейблам `service`, `team`, `env` → каналы команд в Alertmanager (Telegram/Slack/Email).
------------------------------------------------------------------------

## Эксплуатационные практики
- **Хранение и ретеншн**: краткосрочно в Prometheus (например, 15–30 дней), долго — в VictoriaMetrics/Thanos (месяцы/годы).
- **Надёжность**: репликация/HA инстансов, раздельные роли (ingest/query/storage).
- **Управление шумом**: deadman’s switch, дублирование алертов, подавления и maintenance-вокна.
- **Версионирование**: дашборды и правила алёртов храним как код (GitOps), поставка через CI/CD.
- **Безопасность**: rbac в Grafana, ограничение датасорсов, TLS/аутентификация на endpoints.
------------------------------------------------------------------------

## Альтернативы и когда их выбирать
- **SaaS (Datadog, New Relic, Cloud Monitoring)** — минимальная операционная нагрузка, быстрый старт; выше стоимость.
- **Zabbix** — Zabbix — хорошо подходит для классического мониторинга серверов и инфраструктуры, но менее удобен для микросервисной архитектуры. В отличие от Prometheus, у него ограниченная поддержка динамического обнаружения сервисов и контейнеров, меньше готовых экспортёров и нет гибкого языка запросов (PromQL), что делает его менее универсальным в современных системах.
