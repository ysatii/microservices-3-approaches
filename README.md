# Домашнее задание к занятию «Микросервисы: подходы» - Мельник Юрий Александрович

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Решение 1
 

## Обоснование выбора инструментов

Мы выбрали **GitHub Enterprise Cloud** (альтернативно --- **GitLab
SaaS**) как основную платформу.\
**Почему именно так:** - Это облачные решения, которые удовлетворяют
требованию «облачная система».\
- Они поддерживают **Git** и позволяют создавать **отдельные репозитории
на каждый сервис**.\
- Есть встроенные **CI/CD-конвейеры** (GitHub Actions / GitLab CI) с
поддержкой параллельных сборок и тестов.\
- Обеспечивается **безопасное хранение секретов** и интеграция с
облаками через OIDC.\
- Поддерживаются **self-hosted runners**, что даёт гибкость и контроль.\
- Реализована возможность **шаблонов пайплайнов** и **кастомных шагов**,

------------------------------------------------------------------------

1) Структура репозиториев

Мы создадим **отдельный репозиторий на каждый микросервис**, внутри: -
`Dockerfile` для сборки контейнера, - CI/CD workflow
(`.github/workflows/*.yml` или `.gitlab-ci.yml`), - директория `ci/` для
вспомогательных скриптов.

------------------------------------------------------------------------
 2) Конвейер окружений

Мы настроим окружения: **Dev → Integration → UAT → Production**.\
На каждом этапе будет выполняться:\
- Unit-тесты (Dev),\
- интеграционные тесты (Integration),\
- нагрузочные и приёмочные тесты (UAT),\
- выкладка (Production).\
Такой процесс соответствует лекции: «цепочка поставки: код → сборка →
тесты → установка на тестовый контур → интеграция/нагрузка → ручная
приёмка»【34†source】.

------------------------------------------------------------------------

 3) Секреты и параметры

-   Секреты храним в секрет-хранилище GitHub/GitLab (per-env).\
-   Для облаков используем OIDC вместо статических ключей.\
-   Для ручных запусков добавляем `workflow_dispatch`/manual jobs с
    параметрами (окружение, стратегия выката).

------------------------------------------------------------------------

 4) Шаблоны пайплайнов

Мы создадим общий репозиторий `ci-templates` с reusable workflows
(GitHub) или includes (GitLab).\
Это позволит: - поддерживать единый стиль пайплайнов,\
- легко добавлять новые сервисы,\
- держать несколько конфигураций из одного репозитория.

------------------------------------------------------------------------

 5) Агенты и параллельность

-   Используем облачные раннеры.\
-   Для приватных сетей или тяжёлых билдов --- self-hosted runners.\
-   Для параллельности используем `matrix` и шардирование тестов.

------------------------------------------------------------------------

6) Контейнерные образы и артефакты

-   Собираем и публикуем Docker-образы в приватный реестр (GHCR/GLCR).\
-   Артефакты (отчёты тестов, пакеты) храним в артефактории.

------------------------------------------------------------------------

7) Тесты по пирамиде

В проекте реализована пирамида тестирования, включающая три уровня проверок:
**Unit-тесты** — быстрые и массовые проверки отдельных функций и модулей, запускаются на каждом изменении кода.

**Интеграционные/сервисные тесты** — проверяют взаимодействие микросервисов и работу API.

End-to-End (E2E) тесты** — сквозные сценарии, эмулирующие поведение пользователя.

Такой подход позволяет выявлять большинство ошибок на ранних этапах разработки, сокращает время обратной связи и снижает стоимость исправлений.
Согласно лекции, тесты являются неотъемлемой частью процесса развёртывания, а цепочка сборки должна прерываться как можно раньше при выявлении ошибо
------------------------------------------------------------------------

8) Стратегии выката (CD)

Мы будем использовать:\
- **Rolling** --- плавное обновление,\
- **Blue-Green** --- мгновенное переключение,\


СRolling и Blue-Green --- лучшие базовые стратегии для
продакшена чтобы выкат не сильно был заметен для пользователя
------------------------------------------------------------------------

9) Кастомные шаги
Мы добавим кастомные шаги: миграции БД, генерация документации, 
прогрев кэшей. - при необходимости
------------------------------------------------------------------------

10) Безопасность

-   Включим SAST и dependency scanning.\
-   Сканирование Docker-образов (Trivy).\
-   Подпись образов и политики admission (OPA/Gatekeeper).\
-   Единый подход к аутентификации сервисов (SSO, OAuth2, mTLS, API
    Keys)【34†source】.
------------------------------------------------------------------------



## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Решение 2

Реализуем централизованный сбор и анализ логов на базе **ELK**: агенты (Filebeat/Fluent Bit) на каждом хосте → **Logstash** (парсинг/нормализация) → **Elasticsearch** (центральное хранилище и поиск) → **Kibana** (пользовательский интерфейс). Решение покрывает требования по сбору из *stdout*, гарантии доставки, поиску/фильтрации и предоставлению сохранённых поисков по ссылке.


1) Поток данных**
1. **Агенты на узлах**: Filebeat/Fluent Bit считывают контейнерные логи из *stdout* и системные журналы; добавляют метаданные (сервис, окружение, хост, pod/контейнер при использовании Kubernetes).
2. **Обработка**: данные поступают в **Logstash**, где выполняются парсинг форматов (JSON, текст), нормализация полей, маскирование чувствительных данных и обогащение (при необходимости).
3. **Хранилище и поиск**: **Elasticsearch** индексирует записи и обеспечивает быстрый полнотекстовый поиск и агрегации.
4. **Интерфейс**: **Kibana** предоставляет UI для разработчиков и эксплуатации: поиск, фильтры, визуализации, сохранённые запросы и дашборды (со ссылками для шаринга).

2) Надёжность и доставка**
- Включаем файловые буферы и ретраи на стороне агентов.
- При пиковых нагрузках/жёстких SLA добавляем промежуточный брокер (например, Kafka) между агентами и Logstash для выравнивания нагрузки и гарантированной доставки.
------------------------------------------------------------------------

3) Соответствие требованиям
- **Центральное хранилище со всех хостов** — агенты на каждом узле → Logstash → Elasticsearch (единая точка хранения).
- **Минимальные требования к приложениям** — сбор из *stdout* контейнеров; приложению не требуются изменения.
- **Гарантированная доставка** — буферизация и повторные попытки на агентах; при необходимости — Kafka как «прослойка».
- **Поиск и фильтрация** — полнотекстовый поиск и фильтры в Elasticsearch/Kibana; удобные фасеты по полям/меткам.
- **Пользовательский интерфейс** — Kibana с ролями/правами на пространства/индексы, доступ разработчикам.
- **Сохранённые поиски по ссылке** — сохранение запросов/дашбордов в Kibana и шаринг ссылкой.
------------------------------------------------------------------------

4) Обоснование выбора ELK
1. **Зрелость и распространённость** — стек хорошо известен командам; много документации и экспертизы на рынке.
2. **Гибкая обработка** — Logstash позволяет парсить, нормализовать и обогащать данные под нужды домена.
3. **Мощный поиск/аналитика** — Elasticsearch обеспечивает полнотекстовый посик  и агрегирования (в том числе для отчётности и расследований).
4. **Удобный UX** — Kibana даёт быстрый поиск, визуализации, сохранённые дашборды и общий доступ к ним.
5. **Масштабируемость/HA** — кластеризация Elasticsearch, шардирование и репликация; горизонтальный масштаб.
------------------------------------------------------------------------

5) Эксплуатационные аспекты
- **Политики хранения**: ретеншн по индексам (например, 7–30 дней «горячие» данные, затем «тёплые/холодные» или архив).
- **Безопасность**: разграничение доступа (роли/пространства), маскирование PII на уровне Logstash, шифрование TLS «на входе».
- **Наблюдаемость**: дашборды собственной телеметрии (нагрузка Logstash, состояние кластеров Elasticsearch, объёмы индексов).
- **Стоимость**: планирование диска/IOPS, компрессия, экономия за счёт lifecycle-политик и эконом-класса узлов для «холодных» индексов.
- **Производительность**: бэчинг/конвейер в Logstash, батчи агентов, правильные шаблоны индексов и маппинги полей.
------------------------------------------------------------------------

6) Риски и способы снижения
- **Рост объёма логов** → внедряем фильтрацию «на входе» (drop/редактирование шумных событий), ретеншн и агрегации.
- **«Тяжёлые» запросы в часы пик** → кэширование, ограничения по ролям, выделенные ноды для запросов (hot/warm).
- **Потеря связи с хранилищем** → долговременные файловые буферы агентов; при строгих SLA — Kafka.
- **Чувствительные данные** → маскирование/редакция в Logstash, строгие роли и аудит.
------------------------------------------------------------------------





## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.
